import numpy as np
import pandas as pd

from utilsforecast.evaluation import evaluate
from utilsforecast.plotting import plot_series
from utilsforecast.losses import mae, mse, mape, rmse, smape
from nixtla import NixtlaClient
import streamlit as st

nixtla_client = NixtlaClient('nixak-vgekzclAmNcdPsAOSfaQ7WcDXWgGjU6X5peo92QoKCUKG4wDFq3AO1yU6GXStQRyGPHVw21Zao78DknY'
    # api_key = 'my_api_key_provided_by_nixtla'
)

# Configura√ß√µes gerais da p√°gina
st.set_page_config(
    page_title="TimeGPT Predizendo Licenciamentos para Segmento de Autom√≥veis",
    page_icon="üöó",
    layout="wide"
)

col1, col2 = st.columns([1,1], gap= 'large')

with col1:
   
    st.header('TimeGPT: Predizendo Licenciamentos para Segmento de Autom√≥veis', divider= 'green')
    st.header("_TimeGPT_ is :blue[cool] :sunglasses:")
    st.markdown('''O TimeGPT √© uma ferramenta avan√ßada de previs√£o que utiliza t√©cnicas de machine learning e an√°lise de s√©ries temporais para prever licenciamentos no segmento de autom√≥veis. Com base em dados hist√≥ricos e vari√°veis econ√¥micas, o TimeGPT oferece previs√µes precisas e confi√°veis, auxiliando empresas e √≥rg√£os reguladores a tomar decis√µes informadas. A ferramenta √© capaz de identificar padr√µes e tend√™ncias, proporcionando insights valiosos para o planejamento estrat√©gico e a otimiza√ß√£o de recursos no setor automotivo.
''')

with col2:    
       
    st.image('https://ph-files.imgix.net/de28c977-5ecb-4f2b-a1fb-e744d6181f3f.png?auto=format&fit=crop', width=800)

nixtla_client.validate_api_key()

df = pd.read_excel(r'C:\Tablets\lic_Ve√≠culos_1.xlsx')
df = df.rename(columns={"M√™s": "ds"})

col1, col2 = st.columns([1,2], gap='large')

df['ds'] = pd.to_datetime(df['ds'])
series_cols = ['Autom√≥veis']
df_long = df.melt(id_vars='ds', value_vars=series_cols, var_name='unique_id', value_name='y')

st.header('Dataframe e Gr√°fico - Licenciamento Autom√≥veis', divider='red')

col1, col2 = st.columns([1,2.5], gap='large')

with col1:
    st.write('Dataframe Padr√£o TimeGPT')
    st.dataframe(df_long, height=500)

with col2:
    st.write('Gr√°fico Licenciamentos Autom√≥veis')
    st.image("C:\Tablets\data_auto.png", width= 1500)

st.header('Identifica√ß√£o de Anomalias', divider='gray')

col1, col2 = st.columns([1.2,2], gap= 'large')

with col1:
    st.markdown('''TimeGPT √© uma ferramenta avan√ßada de previs√£o e detec√ß√£o de anomalias em s√©ries temporais. A detec√ß√£o de anomalias √© uma tarefa crucial que identifica pontos fora do comportamento normal da s√©rie, sendo essencial em diversas aplica√ß√µes, como ciberseguran√ßa e monitoramento de equipamentos.
Aqui est√£o os principais pontos sobre a detec√ß√£o de anomalias com TimeGPT:
- **Identifica√ß√£o de Pontos An√¥malos**: TimeGPT utiliza intervalos de confian√ßa para determinar se um ponto √© an√¥malo. Se um ponto cai fora desse intervalo, ele √© considerado uma anomalia.
''')
    st.write('Dataframe Anomalias Licenciamentos Autom√≥veis')    
    anomalies_df = nixtla_client.detect_anomalies(df_long, freq='ME', level=90)
    st.dataframe(anomalies_df, height=1000)
    nixtla_client.plot(df_long, anomalies_df)

with col2:
    st.write('Gr√°fico Anomalias Licenciamentos Autom√≥veis')
    st.markdown('''A imagem parece ser uma s√©rie temporal com o comportamento da vari√°vel "Target [y]" ao longo do tempo (em segundos), comparando os dados reais com uma previs√£o gerada por um modelo **TimeGPT**.

---

### 1. **Componentes principais do gr√°fico**  
- **Linha azul escura (`y`)**: Representa os valores reais da vari√°vel ao longo do tempo.  
- **Linha rosa (`TimeGPT`)**: Representa os valores preditos pelo modelo TimeGPT.  
- **Faixa rosa clara (`TimeGPT_level_90`)**: Intervalo de confian√ßa de 90% para a previs√£o.  
- **Pontos vermelhos (`TimeGPT_anomalies_level_90`)**: Pontos identificados como anomalias pelo modelo.

---

### 2. **Comportamento observado**  
- **Per√≠odos de queda e recupera√ß√£o**:  
   - Houve uma **queda acentuada** nos valores reais em torno de **2020**, seguida de uma recupera√ß√£o gradual.  
   - A queda pode estar associada a algum evento espec√≠fico, a Covid 19.  
- **Previs√µes do modelo TimeGPT**:  
   - A previs√£o segue razoavelmente pr√≥xima dos valores reais, exceto em pontos onde ocorrem **anomalias**.
   - A faixa rosa (intervalo de confian√ßa) se **alarga** em per√≠odos de maior incerteza.  
- **Anomalias**:  
   - Os **pontos vermelhos** indicam discrep√¢ncias significativas entre o valor real e o previsto.  
   - As anomalias s√£o mais evidentes em per√≠odos de queda extrema e recupera√ß√£o em 2020.

---

### 3. **Conclus√µes**  
- O modelo TimeGPT capturou bem o padr√£o geral da s√©rie temporal, inclusive suas tend√™ncias e varia√ß√µes.  
- As **anomalias** coincidem com per√≠odos de comportamento at√≠pico, indicando momentos de **quebra de padr√£o** ou **eventos inesperados**.  
- O **intervalo de confian√ßa** se expande em pontos de maior variabilidade ou incerteza, refletindo um comportamento esperado para previs√µes.

---

### 4. **Pr√≥ximos passos sugeridos**  
- **Analisar as causas das anomalias**: Investigue os eventos externos ou internos que possam ter causado os desvios significativos em 2020.  
- **Refinar o modelo**: Pode-se ajustar o modelo ou usar t√©cnicas adicionais para tratar per√≠odos an√¥malos.  
- **Avaliar a faixa de incerteza**: A amplia√ß√£o do intervalo sugere que a variabilidade aumenta em certas regi√µes, o que pode indicar sazonalidade ou ru√≠dos.
''')
   
    st.image('C:\\Tablets\\anomalias.png', width=1300)


nixtla_client.plot(df_long, time_col='ds', target_col='y')

timegpt_fcst_df = nixtla_client.forecast(df=df_long, h=36, freq='MS', 
                                         time_col='ds', 
                                         target_col='y',
                                         add_history=True, 
                                         level=[80, 90, 95])

st.header('Forecast TimeGPT', divider='blue')

col1, col2 = st.columns([2,2], gap='large')

with col1:
    st.write("Dataframe Forecast Licenciamentos Autom√≥veis TimeGPT - Intervalo de Confian√ßa 80, 90 e 95%")
    st.dataframe(timegpt_fcst_df, height=800)

with col2:

    st.write('Gr√°fico Forecast Licenciamentos Autom√≥veis TimeGPT')
    st.image('C:\\Tablets\\fcsttimegpt.png', width=1000)
    st.markdown('''### An√°lise do Gr√°fico

O gr√°fico representa a s√©rie temporal da vari√°vel **"Target [y]"** ao longo do tempo e as previs√µes geradas pelo modelo **TimeGPT**. Os componentes visuais fornecem insights importantes sobre o comportamento dos dados e o desempenho do modelo.

---

### Componentes principais do gr√°fico:
1. **Linha azul escura (`y`)**: Representa os valores **reais** da vari√°vel ao longo do tempo.
2. **Linha rosa (`TimeGPT`)**: Representa as previs√µes feitas pelo modelo **TimeGPT**.
3. **Faixas rosa claras**:  
   - **TimeGPT_level_80**: Intervalo de confian√ßa de 80%.  
   - **TimeGPT_level_90**: Intervalo de confian√ßa de 90%.  
   - **TimeGPT_level_95**: Intervalo de confian√ßa de 95%.  
   Quanto mais claro o tom da faixa, maior o n√≠vel de confian√ßa (maior a incerteza).

---

### Comportamento Observado:
1. **Tend√™ncia Geral**:  
   - A s√©rie temporal real (**linha azul**) apresenta um comportamento com varia√ß√µes ao longo do tempo, com uma **queda brusca** em torno de **2020**, possivelmente devido a algum evento externo, seguida de uma recupera√ß√£o gradual.

2. **Previs√µes (TimeGPT)**:  
   - O modelo **TimeGPT** acompanha bem os valores reais ap√≥s a queda, mostrando que ele capturou adequadamente a tend√™ncia e sazonalidade presentes nos dados.  
   - A linha rosa est√° pr√≥xima da linha azul real, indicando boa precis√£o na previs√£o.

3. **Intervalos de Confian√ßa**:  
   - As **faixas rosa claras** representam a incerteza nas previs√µes.  
   - Durante o per√≠odo de **2025 em diante**, as faixas de incerteza aumentam gradativamente, refletindo a **maior incerteza** associada a previs√µes de longo prazo.  
   - O intervalo de confian√ßa de **95% (faixa mais clara)** √© visivelmente mais amplo, o que √© esperado em previs√µes estat√≠sticas.

4. **Impacto do Per√≠odo de Queda**:  
   - A queda acentuada em **2020** pode ter influenciado o modelo, mas ele ainda conseguiu projetar valores consistentes no per√≠odo de recupera√ß√£o.

---

### Conclus√µes:
1. O modelo **TimeGPT** est√° **desempenhando bem**, pois suas previs√µes acompanham a s√©rie real com um bom n√≠vel de proximidade.
2. O aumento na **incerteza das previs√µes** ao longo do tempo √© normal e deve ser considerado na interpreta√ß√£o dos resultados.  
3. A **queda em 2020** deve ser analisada com mais detalhes, pois pode indicar a influ√™ncia de eventos externos ou anomalias que podem distorcer a s√©rie hist√≥rica.

---

### Recomenda√ß√µes:
1. **Analisar eventos externos**: Investigue o que ocorreu no per√≠odo de 2020 que provocou a queda abrupta.
2. **Avaliar a qualidade das previs√µes**: Calcule m√©tricas como **RMSE**, **MAE**, ou **MAPE** para quantificar a precis√£o do modelo.
3. **Cen√°rios futuros**: Utilize o intervalo de confian√ßa para considerar diferentes cen√°rios (otimista e pessimista) em planejamentos futuros.
''')


nixtla_client.plot(df_long, timegpt_fcst_df, 
                   time_col='ds', 
                   target_col='y',
                   level=[80, 90, 95])


import pandas as pd
import numpy as np
from sklearn.metrics import mean_squared_error, mean_absolute_error

st.header('M√©tricas de Previs√£o - Mean Squared Error, Mean Absolute Error, Mean Absolute Percent Error, Room Mean Squared Error, Bias, Bias_Rated, Simetric Mape', divider= 'green')

col1, col2= st.columns([2,2], gap='large')

metricas = pd.read_excel(r'C:\Tablets\auto_timegpt_metricas.xlsx')
metricas = metricas.rename(columns={"M√™s": "ds"})
   
# Calcular os erros
y_true = metricas['Autom√≥veis']
y_pred = metricas['y_pred']

# M√©tricas
mse = mean_squared_error(y_true, y_pred)  # Mean Squared Error
mae = mean_absolute_error(y_true, y_pred)  # Mean Absolute Error
rmse = np.sqrt(mse)  # Root Mean Squared Error

# MAPE (Mean Absolute Percentage Error)
mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100

# SMAPE (Symmetric Mean Absolute Percentage Error)
smape = np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred))) * 100

# BIAS (Mean Bias Deviation)
bias = np.mean(y_pred - y_true)

# Bias Rated
bias_rated = (bias / np.mean(y_true)) * 100

# Exibir os resultados
print(f"Mean Squared Error (MSE): {mse:.2f}")
print(f"Mean Absolute Error (MAE): {mae:.2f}")
print(f"Root Mean Squared Error (RMSE): {rmse:.2f}")
print(f"Mean Absolute Percentage Error (MAPE): {mape:.2f}%")
print(f"Symmetric Mean Absolute Percentage Error (SMAPE): {smape:.2f}%")
print(f"Bias: {bias:.2f}")
print(f"Bias_rated: {bias_rated:.2f}%")

with col1:

# Exibindo as m√©tricas com Streamlit
    st.write("### M√©tricas de Avalia√ß√£o do Modelo")  # T√≠tulo

    st.write(f"**Mean Squared Error (MSE):** {mse:.2f}")
    st.write(f"**Mean Absolute Error (MAE):** {mae:.2f}")
    st.write(f"**Root Mean Squared Error (RMSE):** {rmse:.2f}")
    st.write(f"**Mean Absolute Percentage Error (MAPE):** {mape:.2f}%")
    st.write(f"**Symmetric Mean Absolute Percentage Error (SMAPE):** {smape:.2f}%")
    st.write(f"Bias: {bias:.2f}")
    st.write(f"**Bias Rated:** {bias_rated:.2f}%")
    st.markdown('''### An√°lise das M√©tricas de Avalia√ß√£o do Modelo

Os valores fornecidos representam as **m√©tricas de erro e vi√©s** do modelo. Vamos analis√°-los individualmente e interpretar sua qualidade para o desempenho do modelo.
---

### **1. Mean Squared Error (MSE): 1.166.382.887,23**
- **Defini√ß√£o**: O MSE mede o erro quadr√°tico m√©dio entre os valores reais e preditos.  
- **Interpreta√ß√£o**:  
   - O valor elevado do **MSE** indica que existem erros significativos entre as previs√µes e os valores reais.  
   - Por ser quadr√°tico, essa m√©trica √© muito sens√≠vel a **outliers** (erros muito grandes), o que pode estar inflando o valor.

---

### **2. Mean Absolute Error (MAE): 23.750,46**
- **Defini√ß√£o**: Mede o erro absoluto m√©dio entre os valores reais e preditos, mantendo a unidade dos dados.  
- **Interpreta√ß√£o**:  
   - O **MAE de 23.750,46** significa que, em m√©dia, o modelo apresenta um erro de **23.750 unidades**.  
   - Embora seja mais f√°cil de interpretar que o MSE, esse valor ainda pode ser considerado alto dependendo da escala dos dados.

---

### **3. Root Mean Squared Error (RMSE): 34.152,35**
- **Defini√ß√£o**: O RMSE √© a raiz quadrada do MSE, trazendo o erro para a mesma unidade dos dados.  
- **Interpreta√ß√£o**:  
   - O **RMSE de 34.152,35** representa a **magnitude m√©dia do erro**.  
   - Como o RMSE d√° maior peso a grandes erros, ele √© sempre maior ou igual ao MAE.  
   - A diferen√ßa entre RMSE e MAE sugere que existem **outliers** ou previs√µes muito distantes dos valores reais.
''')
    
with col2:
    st.markdown('''### **4. Mean Absolute Percentage Error (MAPE): 20,57%**
- **Defini√ß√£o**: O MAPE mede o erro percentual m√©dio entre os valores reais e previstos.  
- **Interpreta√ß√£o**:  
   - Um **MAPE de 20,57%** indica que, em m√©dia, as previs√µes est√£o **20,57% fora** dos valores reais.  
   - Esse valor est√° na faixa aceit√°vel, mas sugere que o modelo pode ser melhorado.  
   - Modelos com MAPE abaixo de **10%** s√£o considerados muito precisos, entre **10% e 20%** s√£o razo√°veis, e acima de **20%** podem indicar dificuldades.        
                
### **5. Symmetric Mean Absolute Percentage Error (SMAPE): 15,59%**
- **Defini√ß√£o**: O SMAPE √© uma vers√£o ajustada do MAPE que considera tanto os valores reais quanto os previstos.  
- **Interpreta√ß√£o**:  
   - O **SMAPE de 15,59%** confirma que o erro percentual √© moderado.  
   - Valores pr√≥ximos a **15%** indicam que o modelo tem um desempenho razo√°vel, mas h√° espa√ßo para melhorias.

---

### **6. Bias: 9.330,23**
- **Defini√ß√£o**: O **Bias** representa a m√©dia das diferen√ßas entre os valores previstos e reais. Ele indica se o modelo tende a **superestimar** ou **subestimar** os valores.  
- **Interpreta√ß√£o**:  
   - O valor positivo de **9.330,23** sugere que o modelo apresenta um **vi√©s positivo**, ou seja, as previs√µes s√£o, em m√©dia, **9.330 unidades maiores** que os valores reais.  
   - Esse vi√©s √© significativo e deve ser analisado mais profundamente.

---

### **7. Bias Rated: 6,02%**
- **Defini√ß√£o**: O **Bias Rated** representa o vi√©s percentual, indicando a propor√ß√£o m√©dia em que as previs√µes est√£o superestimadas ou subestimadas.  
- **Interpreta√ß√£o**:  
   - O **Bias Rated de 6,02%** significa que, em m√©dia, o modelo **superestima os valores reais em 6,02%**.  
   - Embora o valor n√£o seja excessivamente alto, √© um sinal de que o modelo apresenta tend√™ncia de **superestima√ß√£o constante**.

### **Conclus√£o Geral**
Com base nas m√©tricas fornecidas:
- O **erro absoluto (MAE: 23.750,46)** e o **erro quadr√°tico (RMSE: 34.152,35)** est√£o altos, sugerindo que o modelo possui erros significativos.  
- O **erro percentual** (MAPE: 20,57% e SMAPE: 15,59%) mostra que o modelo tem um desempenho **razo√°vel**, mas longe de ser excelente.  
- O **vi√©s positivo** (Bias: 9.330,23 e Bias Rated: 6,02%) indica que o modelo tem uma tend√™ncia de **superestimar** os valores reais.
''')

timegpt_fcst_finetune_mae_df = nixtla_client.forecast(
    df=df_long, 
    h=36, 
    finetune_steps=60,
    finetune_loss='mae',   # Set your desired loss function
    finetune_depth=1,
    time_col='ds', 
    target_col='y',
    level=[80, 90, 95],
    add_history=True
)


timegpt_fcst_finetune_mae_df.to_excel('C:\Tablets/autotimegptfinetun1.xlsx', index=False)
nixtla_client.plot(df_long, timegpt_fcst_finetune_mae_df, 
                   time_col='ds', 
                   target_col='y',
                   level=[80, 90, 95])

import pandas as pd
from sklearn.metrics import mean_absolute_error as mae, mean_squared_error as mse
import numpy as np

# Divis√£o do conjunto de dados em treino e teste
train = df_long[:-36]
test = df_long[-36:]

# Exibir as partes de treino e teste
print("Train Data:")
print(train.head())

print("\nTest Data:")
print(test.head())

# Visualiza√ß√£o dos dados
plot_series(train[['unique_id', 'ds', 'y']], 
            forecasts_df=test[['unique_id', 'ds', 'y']].rename(columns={'y': 'test'}))

# Lista de perdas a serem testadas
losses = ['default', 'mae', 'mse', 'rmse', 'mape', 'smape']

# Criar uma c√≥pia do conjunto de teste para inserir previs√µes
test = test.copy()

# Loop para realizar previs√µes com diferentes fun√ß√µes de perda
for loss in losses:
    preds_df = nixtla_client.forecast(
        df=train, 
        h=36, 
        finetune_steps=60,    
        finetune_loss=loss,
        time_col='ds', 
        target_col='y'
    )
    preds = preds_df['TimeGPT'].values  # Obter as previs√µes
    test.loc[:, f'TimeGPT_{loss}'] = preds  # Armazenar previs√µes no conjunto de teste

# Dicion√°rio de fun√ß√µes de perda
def rmse(y_true, y_pred):
    return np.sqrt(mse(y_true, y_pred))

def mape(y_true, y_pred):
    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100

def smape(y_true, y_pred):
    return np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred))) * 100

loss_fct_dict = {
    "mae": lambda test, c1, c2: mae(test['y'], test[c2]),
    "mse": lambda test, c1, c2: mse(test['y'], test[c2]),
    "rmse": lambda test, c1, c2: rmse(test['y'], test[c2]),
    "mape": lambda test, c1, c2: mape(test['y'], test[c2]),
    "smape": lambda test, c1, c2: smape(test['y'], test[c2])
}

# Avalia√ß√£o e c√°lculo da melhoria percentual
pct_improv = []

for loss in losses[1:]:
    eval_default = loss_fct_dict[loss](test, 'y', 'TimeGPT_default')
    eval_loss = loss_fct_dict[loss](test, 'y', f'TimeGPT_{loss}')
    
    pct_diff = (eval_default - eval_loss) / eval_default * 100
    pct_improv.append(round(pct_diff, 2))

# Constru√ß√£o do DataFrame final com as melhorias
data = {
    'mae': pct_improv[0],
    'mse': pct_improv[1],
    'rmse': pct_improv[2],
    'mape': pct_improv[3],
    'smape': pct_improv[4]
}

metrics_df = pd.DataFrame(data, index=['Metric Improvement (%)'])

# Exibir as m√©tricas de melhoria
print("\nMetrics Improvement DataFrame:")
print(metrics_df)

st.header('Aprimorando a Modelagem por Meio do TimeGPT FineTuning_steps = 60, FineTuning_Mae e FineTuning_depths = 1', divider= 'violet')

col1, col2 = st.columns([1.5,4], gap='large')
    
with col1: 
    st.write('"_TimeGPT FineTuning - Aprimorando Previs√µes_ √© :blue[top] :sunglasses:"')
    st.dataframe(metrics_df)

    st.markdown('''### **Resumo Explicativo das Vantagens do FineTuning**

O c√≥digo apresentado tem como objetivo **avaliar e comparar o desempenho do modelo TimeGPT** ao usar diferentes **fun√ß√µes de perda (loss functions)** durante o ajuste fino (**fine-tuning**). Abaixo est√£o as principais vantagens e benef√≠cios desse c√≥digo:

---

### **1. Teste de Diferentes Fun√ß√µes de Perda**
- O c√≥digo permite avaliar o impacto de diferentes fun√ß√µes de perda (**MAE, MSE, RMSE, MAPE, SMAPE**) no desempenho do modelo.
- Isso possibilita **identificar a melhor fun√ß√£o de perda** para um determinado conjunto de dados e contexto.
- A abordagem √© flex√≠vel, pois utiliza uma lista de fun√ß√µes que pode ser facilmente expandida.

**Benef√≠cio**: Melhoria da precis√£o das previs√µes ao escolher a fun√ß√£o de perda mais adequada.

---

### **2. Automa√ß√£o do Processo de Avalia√ß√£o**
- A estrutura de loop automatiza a **realiza√ß√£o das previs√µes** com todas as fun√ß√µes de perda definidas.
- M√©tricas de desempenho s√£o calculadas automaticamente para cada previs√£o e armazenadas de forma organizada.

**Benef√≠cio**: Ganho de **efici√™ncia e produtividade**, eliminando a necessidade de ajustar manualmente o modelo v√°rias vezes.

---

### **3. Compara√ß√£o com um Padr√£o (`default`)**
- O desempenho das previs√µes ajustadas √© comparado diretamente com a previs√£o padr√£o (`TimeGPT_default`).
- Isso permite calcular a **melhoria percentual** obtida ao usar diferentes fun√ß√µes de perda.

**Benef√≠cio**: Facilita a **quantifica√ß√£o dos ganhos de desempenho** e torna a compara√ß√£o mais objetiva.

---

### **4. Avalia√ß√£o com M√∫ltiplas M√©tricas**
- O c√≥digo calcula v√°rias m√©tricas de erro:
  - **MAE**: Mede o erro absoluto m√©dio, f√°cil de interpretar.
  - **MSE** e **RMSE**: Penalizam erros maiores, sendo √∫teis para previs√µes sens√≠veis a grandes desvios.
  - **MAPE** e **SMAPE**: Fornecem erros percentuais, facilitando a compara√ß√£o entre diferentes escalas de dados.
- O uso de m√∫ltiplas m√©tricas garante uma avalia√ß√£o mais completa e balanceada do desempenho.

**Benef√≠cio**: Garante uma **an√°lise robusta** do modelo ao n√£o depender de uma √∫nica m√©trica.

---

### **5. Estrutura Clara e Organizada**
- As previs√µes s√£o armazenadas em colunas espec√≠ficas no conjunto de teste, facilitando a organiza√ß√£o dos dados.
- O c√°lculo de melhorias percentuais √© armazenado em um **DataFrame** final, o que facilita a interpreta√ß√£o dos resultados.

**Benef√≠cio**: **Visualiza√ß√£o f√°cil** e organizada dos resultados, ideal para an√°lise e apresenta√ß√£o.

---

### **6. Adapta√ß√£o a Diferentes Contextos**
- O c√≥digo √© facilmente adapt√°vel a outros modelos ou conjuntos de dados.
- Novas fun√ß√µes de perda ou m√©tricas podem ser adicionadas ao c√≥digo sem grandes modifica√ß√µes.

**Benef√≠cio**: **Versatilidade** para aplica√ß√µes em diferentes contextos e necessidades.

---

### **Conclus√£o**
O c√≥digo oferece uma abordagem automatizada, flex√≠vel e robusta para **avaliar o impacto de diferentes fun√ß√µes de perda** em um modelo de previs√£o. Com ele, √© poss√≠vel **identificar a melhor estrat√©gia** de ajuste fino para melhorar a precis√£o das previs√µes, economizando tempo e facilitando a an√°lise dos resultados. Essa pr√°tica √© extremamente √∫til em problemas de s√©ries temporais e ajuda a tomar decis√µes mais embasadas no desempenho do modelo.
''')



import pandas as pd
from nixtla import NixtlaClient
from utilsforecast.losses import mae, mse
from utilsforecast.evaluation import evaluate

pd.options.display.float_format = '{:,.2f}'.format

depths = [1, 2, 3, 4, 5]

test = test.copy()

for depth in depths:
    preds_df = nixtla_client.forecast(
    df=train, 
    h=36, 
    finetune_steps=5,
    finetune_depth=depth,
    time_col='ds', 
    target_col='y')

    preds = preds_df['TimeGPT'].values

    test.loc[:,f'TimeGPT_depth{depth}'] = preds

    test['unique_id'] = 0

evaluation = evaluate(test, metrics=[mae, mse], time_col="ds", target_col="y")
with col2:
    st.write('"_TimeGPT FineTuning - Aprimorando Previs√µes_ √© :blue[top] :sunglasses:"')
    st.dataframe(evaluation)
    st.markdown('''### **An√°lise do DataFrame de Melhoria das M√©tricas**

O DataFrame **Metrics Improvement** apresenta os resultados da **melhoria percentual** de diversas m√©tricas de erro ao comparar previs√µes feitas com diferentes fun√ß√µes de perda em rela√ß√£o √† previs√£o padr√£o (`TimeGPT_default`). As m√©tricas avaliadas s√£o **MAE**, **MSE**, **RMSE**, **MAPE** e **SMAPE**.

A seguir, analisaremos os resultados de cada m√©trica:

---

### **1. MAE (Mean Absolute Error)**
- **Melhoria percentual**: **2.89%**
- O **MAE** √© uma m√©trica que mede o erro absoluto m√©dio das previs√µes. Uma melhoria de **2.89%** indica que a fun√ß√£o de perda utilizada **reduziu ligeiramente o erro absoluto m√©dio** em rela√ß√£o ao modelo padr√£o. Embora a melhoria n√£o seja muito grande, qualquer redu√ß√£o no erro absoluto √© geralmente desej√°vel, especialmente quando se trata de prever valores com unidades reais.

**Interpreta√ß√£o**: A fun√ß√£o de perda testada **contribuiu de forma modesta para melhorar a precis√£o** do modelo em termos de erro absoluto.

---

### **2. MSE (Mean Squared Error)**
- **Melhoria percentual**: **9.1%**
- O **MSE** penaliza erros maiores mais severamente do que o MAE, tornando-o √∫til para identificar modelos que cometem grandes erros. Uma melhoria de **9.1%** sugere que a fun√ß√£o de perda foi eficaz em **reduzir os erros quadr√°ticos**, indicando que a fun√ß√£o de perda testada ajudou a diminuir os grandes desvios, o que pode ser crucial em muitos problemas de previs√£o, especialmente em s√©ries temporais.

**Interpreta√ß√£o**: A fun√ß√£o de perda testada teve um impacto **mais significativo** na redu√ß√£o de grandes erros.

---

### **3. RMSE (Root Mean Squared Error)**
- **Melhoria percentual**: **3.37%**
- O **RMSE** √© a raiz quadrada do MSE e mede o erro m√©dio, dando mais peso aos grandes erros. Uma melhoria de **3.37%** significa que, embora tenha havido uma redu√ß√£o no RMSE, o impacto foi mais **modesto** em compara√ß√£o com a melhoria observada no MSE. O RMSE √© particularmente √∫til para entender o erro em unidades compar√°veis aos valores de sa√≠da.

**Interpreta√ß√£o**: A fun√ß√£o de perda ajudou a **reduzir levemente** o erro m√©dio ponderado, mas a melhoria foi menor que no MSE, o que √© esperado dado que o RMSE tem uma rela√ß√£o mais direta com a escala dos valores.

---

### **4. MAPE (Mean Absolute Percentage Error)**
- **Melhoria percentual**: **59.44%**
- O **MAPE** mede o erro m√©dio percentual, que √© √∫til para avaliar o desempenho de modelos em termos relativos. Uma melhoria de **59.44%** √© bastante significativa, indicando que a fun√ß√£o de perda testada **reduziu drasticamente o erro percentual**. Isso sugere que, ao usar essa fun√ß√£o de perda, as previs√µes do modelo ficaram muito mais **precisas em rela√ß√£o aos valores reais**.

**Interpreta√ß√£o**: A fun√ß√£o de perda testada proporcionou uma **grande melhoria** na precis√£o percentual das previs√µes, o que √© extremamente importante em muitos cen√°rios onde a precis√£o relativa √© crucial.

---

### **5. SMAPE (Symmetric Mean Absolute Percentage Error)**
- **Melhoria percentual**: **8.53%**
- O **SMAPE** √© uma m√©trica similar ao MAPE, mas √© mais equilibrada no tratamento de erros relativos, tratando igualmente os desvios positivos e negativos. A melhoria de **8.53%** indica que a fun√ß√£o de perda testada teve um impacto **moderado** na redu√ß√£o do erro percentual sim√©trico, o que √© ben√©fico, pois evita que o modelo favore√ßa previs√µes tendenciosas em rela√ß√£o a valores altos ou baixos.

**Interpreta√ß√£o**: A fun√ß√£o de perda testada **reduziu o erro sim√©trico** de forma significativa, mas a melhoria foi mais modesta quando comparada ao MAPE.

---

### **Conclus√£o Geral**
- **M√©trica com maior melhoria**: **MAPE (59.44%)**, o que sugere que a fun√ß√£o de perda testada teve um grande impacto na precis√£o percentual das previs√µes.
- **M√©trica com menor melhoria**: **MAE (2.89%)**, que teve uma melhoria modesta, indicando que o erro absoluto m√©dio n√£o foi reduzido de forma t√£o significativa quanto as outras m√©tricas.
- **Impacto das fun√ß√µes de perda**: O modelo demonstrou uma melhoria significativa no desempenho com a fun√ß√£o de perda testada, especialmente nas m√©tricas de erro percentual (**MAPE e SMAPE**), o que pode ser crucial dependendo do tipo de aplica√ß√£o (como previs√£o de demanda ou vendas).

**Conclus√£o final**: A fun√ß√£o de perda testada mostrou-se eficaz em melhorar as previs√µes, especialmente em termos relativos (MAPE e SMAPE), o que pode ser desej√°vel para muitos cen√°rios. Se o foco for **minimizar os grandes erros** ou melhorar a previs√£o percentual, a fun√ß√£o de perda escolhida parece ser a **melhor op√ß√£o** entre as testadas.
''')
    
st.header('Forecast TimeGPT para Licenciamentos Autom√≥veis Aprimorado', divider='green')
col1, col2 = st.columns([1,1], gap='large')
with col1:
    st.write('Nova Previs√£o FineTuning_Steps = 60; FineTuning_Mae e FineTuning_depths = 1')
    st.dataframe(timegpt_fcst_finetune_mae_df, height=500)
    st.markdown('''O c√≥digo fornecido est√° utilizando a biblioteca **Nixtla** (presumivelmente para previs√£o de s√©ries temporais) para realizar previs√µes utilizando o modelo **TimeGPT** com ajuste fino (**fine-tuning**) de par√¢metros, com o foco na **fun√ß√£o de perda MAE**. Vamos analisar cada parte do c√≥digo e explicar sua fun√ß√£o:

---

### **1. Defini√ß√£o da Fun√ß√£o `forecast`**

A fun√ß√£o `nixtla_client.forecast()` √© usada para gerar previs√µes de s√©ries temporais, utilizando diferentes par√¢metros para ajustar o modelo conforme a necessidade. O retorno dessa fun√ß√£o √© um **DataFrame** com as previs√µes feitas pelo modelo.

---

### **2. Par√¢metros do Modelo de Previs√£o**

- **`df=df_long`**: 
  - O par√¢metro `df` representa o conjunto de dados que ser√° utilizado para treinar e gerar previs√µes. No caso, `df_long` √© um DataFrame com os dados da s√©rie temporal, onde `ds` representa a coluna de data e `y` a vari√°vel alvo (o valor que se deseja prever).

- **`h=36`**:
  - O par√¢metro `h` define o **horizonte de previs√£o**, ou seja, o n√∫mero de per√≠odos para os quais o modelo ir√° fazer as previs√µes. No caso, o modelo est√° configurado para prever os pr√≥ximos **36 per√≠odos** (o que pode representar, por exemplo, 36 meses ou 36 dias, dependendo da granularidade dos dados).

- **`finetune_steps=60`**:
  - Esse par√¢metro especifica o n√∫mero de **passos de ajuste fino (fine-tuning)** que o modelo realizar√° para melhorar a precis√£o das previs√µes. O modelo ser√° ajustado durante **60 itera√ß√µes**, o que permite que o modelo se especialize mais nas particularidades dos dados.

- **`finetune_loss='mae'`**:
  - A fun√ß√£o de perda a ser usada durante o processo de ajuste fino. O par√¢metro `'mae'` significa que o modelo ser√° otimizado para minimizar o **Erro Absoluto M√©dio (MAE - Mean Absolute Error)**. O MAE mede a m√©dia dos erros absolutos entre as previs√µes e os valores reais, ou seja, √© uma m√©trica simples e interpret√°vel, adequada para medir a precis√£o do modelo em termos absolutos.

- **`finetune_depth=1`**:
  - A profundidade do ajuste fino. Esse par√¢metro pode controlar a complexidade do modelo durante o treinamento adicional. Um valor de **1** geralmente significa um ajuste mais leve e r√°pido, enquanto valores maiores indicam um ajuste mais profundo e complexo.

- **`time_col='ds'`** e **`target_col='y'`**:
  - Esses par√¢metros especificam as colunas do DataFrame que representam, respectivamente, o **tempo (ds)** e a vari√°vel alvo (**y**). O modelo usa essas colunas para entender as rela√ß√µes entre os dados hist√≥ricos e fazer previs√µes.

- **`level=[80, 90, 95]`**:
  - Esse par√¢metro define os **n√≠veis de confian√ßa** para as previs√µes. No caso, as previs√µes ser√£o feitas com intervalos de confian√ßa de **80%**, **90%** e **95%**. Isso permite que voc√™ tenha uma ideia da **variabilidade das previs√µes**, fornecendo uma faixa de poss√≠veis valores para o futuro, em vez de uma previs√£o √∫nica.

- **`add_history=True`**:
  - O par√¢metro `add_history=True` indica que o modelo deve **incluir dados hist√≥ricos adicionais** ao realizar as previs√µes. Isso √© √∫til para capturar padr√µes sazonais e tend√™ncias que podem estar presentes no passado.

---

### **3. Objetivo do C√≥digo**

O objetivo desse c√≥digo √© treinar o modelo **TimeGPT** utilizando dados hist√≥ricos e realizar previs√µes para os pr√≥ximos 36 per√≠odos. Durante o treinamento, o modelo passar√° por **60 itera√ß√µes de ajuste fino**, sendo otimizado com a fun√ß√£o de perda **MAE**. O modelo tamb√©m gera intervalos de confian√ßa para suas previs√µes, oferecendo uma estimativa mais robusta para os pr√≥ximos valores.

---

### **Vantagens dessa Abordagem**

1. **Ajuste Fino (Fine-tuning)**: 
   - O modelo √© ajustado para otimizar uma m√©trica de erro espec√≠fica (neste caso, o MAE), o que pode melhorar significativamente a qualidade das previs√µes em rela√ß√£o ao modelo b√°sico.

2. **Previs√µes com Intervalos de Confian√ßa**:
   - Ao fornecer previs√µes com diferentes n√≠veis de confian√ßa (**80%, 90%, 95%**), o modelo permite uma an√°lise mais abrangente, considerando a incerteza nas previs√µes.

3. **Considera√ß√£o de Dados Hist√≥ricos**:
   - Ao incluir os dados hist√≥ricos no processo de previs√£o (`add_history=True`), o modelo pode capturar melhor as tend√™ncias e padr√µes sazonais, o que pode melhorar a precis√£o das previs√µes.

4. **Otimiza√ß√£o para MAE**:
   - O MAE √© uma fun√ß√£o de perda intuitiva e muito utilizada em problemas de previs√£o, pois mede diretamente a m√©dia dos erros absolutos, sem penalizar excessivamente os grandes erros (ao contr√°rio do MSE). Isso pode ser √∫til quando os erros de grande magnitude s√£o indesej√°veis.

---

### **Conclus√£o**

Esse c√≥digo utiliza o **TimeGPT** para gerar previs√µes ajustadas com base em dados hist√≥ricos, com o processo de ajuste fino otimizando o modelo de acordo com o **Erro Absoluto M√©dio (MAE)**. As previs√µes geradas v√™m com **intervalos de confian√ßa**, oferecendo uma vis√£o mais completa e robusta sobre o futuro, ao mesmo tempo que s√£o otimizadas para minimizar o erro absoluto. Essa abordagem √© eficaz para melhorar a precis√£o do modelo e fornecer previs√µes com maior confiabilidade.
''')

with col2:
    st.write('Gr√°fico Forecast TimeGPT Aprimorados para Licenciamentos Autom√≥veis')
    st.image('C:\\Tablets\\fcstfine.png', width=1000)
    st.image('C:\\Tablets\\codigo.png', width= 1000)




